## 1.构思

**在一个由提问者和回答者组成的Agent对话中，随着对话轮次的增加，信道的熵（不确定性）会趋于下降。**
这一核心洞察被进一步应用于一个前沿领域：**生成式隐写技术**。具体构想如下：

* **核心目标**：在两个Agent之间的对话中，构建一个不易被察觉的隐蔽信道，用于传递秘密信息。

* **基本原理**：生成式隐写的嵌入容量（能够隐藏多少信息）直接取决于载体信道（此处为对话内容）的熵。熵越高，可供选择的、用于编码信息的“自由度”就越大，可嵌入的信息量也越大。隐写容量的上限公式为$C_A(D)\leq H(D)$

* **关键设计**：选择**目标导向的收敛性对话**（如共同解决一个问题、完成一项任务）作为隐写载体的“掩护故事”。这一设计的精妙之处在于，**相比于发散性的、漫无目的的闲聊，两个机器为了解决一个具体问题而进行逻辑连贯的对话，在外部监控者看来是极其合理和正常的行为，从而提供了绝佳的伪装。**

## 2.熵在对话过程中的变化

* **熵的自然衰减**：在一个**收敛性对话**中，每个回答都在提供信息，消除不确定性。这导致对话的上下文约束越来越强，后续内容的可预测性越来越高，从而使得信道的**预测熵（Predictive Entropy）** 自然地、持续地下降。这意味着，随着对话的进行，**“隐写带宽”会越来越窄**，在对话后期可能几乎为零。由$C_A(D)\leq H(D)$可知，随着对话的进行，**嵌入率是越来越低的**

## 3. 信道熵的量化

为了验证构想并应对挑战，我们必须能够精确地量化信道熵。我们格外关注信道的瞬时熵，原因（FreStaga）：
- 其一，大型语言模型经过指令微调和人类反馈强化学习（RLHF）后，其输出分布常常会变得“锐化” ，即模型在预测下一个词元时会**过度自信**，导致分布的熵降低 。这种确定性过强的输出会减少文本的多样性和创造性，使生成的隐写文本更容易被识别出来 。瞬时熵能够实时反映模型在每一步生成时的不确定性程度 。**隐写术的嵌入容量上限由信道（即语言模型）的熵决定**
 **其实就是瞬时熵和嵌入的容量是直接挂钩的**
### 3.1 瞬时熵 (Microscopic Predictive Entropy)

* **定义**：衡量在给定当前全部对话历史的条件下，语言模型对下一个Token预测的不确定性。
* **测量方法**：
    1.  将当前对话上下文输入一个预训练语言模型（LLM）。
    2.  获取模型输出的下一个Token的概率分布。
    3.  计算该概率分布的**香农熵 (Shannon Entropy)**，公式为 $$H(P) = - \sum p_i \log_2(p_i)$$
    4.  或计算其等价指标**困惑度 (Perplexity, PPL)**，公式为 $$PPL = 2^H$$
## 4. 实验
本节给出完整的实验设计与版本迭代，体现从双侧测量到单侧测量的取舍，以及最终的数据规模、流程与记录方式。
### 4.1 版本A：双侧熵测量（已弃用）
- **基本流程**：
  1. 准备一个初始`topic`。
  2. 将`topic`发送给提问模型（Questioner），在其输出问题前先测一次瞬时熵（下一Token分布的香农熵）。
  3. 提问模型输出问题，将问题发送给回答模型（Responder）。
  4. 回答模型在输出回答前同样测一次瞬时熵，然后生成回答。
  5. 将回答再反馈给提问模型，进入下一轮，循环往复。

- **放弃原因：
  - 计算资源浪费：双侧测量在工程上成本翻倍，但对结论贡献有限。
  - 信息冗余：在目标导向的收敛性对话中，信道收敛趋势可以通过单侧（例如回答侧）瞬时熵充分体现。
  - 系统复杂度与噪声增益：双侧测量引入更多不确定性来源（两端解码差异、接口时延），不利于稳定复现。
### 4.2 版本B：单侧熵测量（采用）
- **核心思路**：仅在回答侧每轮回答之前测量瞬时熵，提问侧通过API生成问题但不再测熵。这样既能刻画信道熵的收敛趋势，又显著节省计算与时间。
- **详细流程**：
  1. 将初始$`topic`$发送给远程提问模型（API调用），获得第`t`轮问题$`q_t`$。
  2. 将当前对话历史与$`q_t`$拼接为回答模型的输入上下文。
  3. 在生成回答之前：前向一次，获取下一Token概率分布，计算瞬时熵$`H_t`$与困惑度$`PPL_t=2^{H_t}`$；记录但不改变解码策略。
  4. 使用与测量一致的解码超参生成回答$`a_t`$；将$`a_t`$追加到对话历史。
  5. 重复步骤1-4，直到达到设定轮数。
- **轮数选择（个人取舍）**：
  - 起初尝试了10/20/30轮作为独立配置；实践后确认“模型并不会因为预设的轮数不同而改变行为”，因此直接固定为30轮，并以“前缀截取”方式得到10轮或20轮的结果，避免重复计算。
- **数据规模**：
  - 10个`topic` × 每`topic`重复3次 × 每次30轮 ≈ 900次瞬时熵观测。
- **模型**：
  - 回答侧采用`Qwen2-7B-Instruct`；提问侧作为独立API服务，仅负责产出问题。
### 4.3 变量与控制
- **自变量**：
  - `topic`的抽象程度与先验不确定性（从高度泛化到具体专业）。
- **因变量**：
  - 每轮回答前的瞬时熵$H_t$，以及对应$PPL_t$；关注其随轮次的下降趋势（收敛性）。
- **控制变量（保持不变）**：
  - 回答模型版本与权重、解码超参、系统提示/上下文拼接格式、采样温度与Top-*k/p*策略、最大生成长度、停止条件、日志与评估代码。
  - 提问API仅更换`topic`与轮次上下文，其余参数固定，尽量降低外部扰动。
### 4.4 主题集合（Topics）
- **覆盖两端分布**：
  - 泛化话题（初始熵高）：如`topic/ai.txt`，范围广、可选展开路径多。
  - 专题话题（初始熵较低）：如`topic/cnn.txt`，问题域更聚焦、上下文约束更强。
- **实际使用**：共准备10个`topic`，覆盖从通用到专业的跨度，以观察起始熵与收敛速度的差异。
- ai
- algorithms
- art
- cnn*
- cybersecurity
- economics
- mathematics*
- nlp_transformers*
- philosophy
### 4.5 运行流程与记录字段

- **对话循环**：对每个`topic`，独立运行30轮；对同一`topic`重复3次以估计方差与稳健性。
- **记录字段（每轮）**：
  - `topic_id`/名称，`round_id`，瞬时熵$`H_t`$，$`PPL_t`$，提问$`q_t`$与回答$`a_t`$文本快照，时间戳，随机种子/会话ID，解码超参摘要。
- **一致性要求**：
  - 测量与生成使用一致的解码超参；测量仅读取分布不改写上下文。
## 5. 结果分析
- 每个主题在全部观测（30轮 × 3次重复）的瞬时熵统计。
- http://localhost:8000/index.html

|topic|mean_entropy_bits|variance_entropy_bits2|
|:----|:----|:----|
|ai|4.244674|0.566287|
|algorithms|3.218629|0.817796|
|art|3.414861|0.822280|
|cnn|3.558681|0.868433|
|cybersecurity|3.727634|0.443121|
|economics|3.797030|0.539704|
|mathematics|3.139925|0.619107|
|nlp_transformers|3.331688|0.748813|

- 综合排序（平均熵高→低，单位bits）
- ai 4.245 > economics 3.797 ≈ cybersecurity 3.728 > cnn 3.559 > art 3.415 > nlp_transformers 3.332 > algorithms 3.219 > mathematics 3.140
- 含义：ai最“开放”、隐写容量上限最高；mathematics最“受约束”、容量上限最低。
- 稳定性（方差低→高，括号为标准差≈）
- 最稳：cybersecurity 0.443（≈0.666），economics 0.540（≈0.735），ai 0.566（≈0.753）
- 波动大：cnn 0.868（≈0.932），art 0.822（≈0.907），algorithms 0.818（≈0.904），nlp_transformers 0.749（≈0.865）


|topic|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|average|
|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|
|ai|4.577141|3.615730|3.972578|3.028259|3.953194|3.637756|4.383044|4.237608|4.194887|4.541942|4.721140|4.808021|3.820022|3.961558|4.622882|4.086463|4.719653|4.609621|3.848487|4.046848|4.714899|4.724140|3.727805|4.506635|4.463206|4.988810|4.314100|3.569984|4.314332|4.629464|4.244674|
|algorithms|2.684024|2.926178|2.702420|2.762005|2.858041|2.176917|2.358932|3.671294|2.982226|2.912171|3.561916|2.715156|3.513107|2.616856|3.575982|2.747583|3.386509|4.133756|4.059639|3.149527|3.648525|2.972779|3.645048|3.341176|2.989424|3.358456|3.909742|3.660053|3.728100|3.811335|3.218629|
|art|2.091791|3.584177|3.439665|3.097729|4.095610|3.648016|2.676772|2.880807|3.103512|3.408654|3.690890|3.208177|3.198897|3.356509|2.660011|2.865874|3.626976|2.903969|3.852536|3.584370|4.022361|3.495867|4.066078|3.735618|3.065465|3.390191|3.962034|3.941893|3.567189|4.224181|3.414861|
|cnn|2.101910|2.927790|2.990221|3.430961|4.089979|4.366074|2.771935|4.447791|4.437790|2.833561|3.372516|3.900150|3.959359|3.912961|3.320091|3.752129|3.961332|3.670667|3.314471|3.095173|2.961007|3.991589|3.416089|3.704835|4.125611|4.165311|3.339220|4.403501|3.428391|2.568022|3.558681|
|cybersecurity|3.669965|3.542491|4.012576|3.811279|3.268381|3.492141|3.682519|3.188371|4.096010|3.544933|4.378286|4.259379|3.539575|3.942350|3.812702|3.755163|4.087339|2.827158|3.562297|3.448354|3.705865|3.833813|3.786825|3.443570|3.764502|4.045427|3.776809|4.031677|3.114500|4.404765|3.727634|
|economics|2.475787|3.493966|4.287488|3.955793|3.420220|4.208097|3.631048|4.162617|3.797563|3.585137|3.628837|3.355840|3.262468|3.861400|4.180550|3.976566|2.945032|4.135960|4.030570|4.300524|4.011043|3.892620|3.918344|4.046688|3.933536|4.216738|3.756367|4.006730|3.816186|3.617170|3.797030|
|mathematics|2.898850|2.373671|2.776122|3.351994|2.731038|3.213214|3.512139|2.866484|2.597529|2.970165|3.319366|3.181117|2.200624|3.798681|3.060404|3.770718|3.058568|3.325678|2.807922|2.997555|3.643179|3.051370|3.921564|3.095776|3.316002|3.436153|2.983152|3.722864|3.811525|2.404331|3.139925|
|nlp_transformers|2.236783|2.663720|3.068536|3.669294|3.549814|3.753520|3.437575|3.393199|2.729361|3.589272|4.033002|2.953702|3.417060|3.069370|4.107027|3.441527|3.540653|3.442490|3.080693|4.042917|3.167107|3.066453|3.186973|3.105795|3.605712|3.832818|3.248637|3.035206|3.420938|3.061476|3.331688|

- 共性：非单调收敛，存在“上冲/回落”，说明对话中阶段性“话题扩展/约束变化”会拉高熵。
- ai（高且稳）：全程高位，后段更强（26轮达4.989，21–22也在4.7+），可作为“最大容量”参考通道。
- economics（高且平稳）：多段平台（8、15、24–26轮高），整体波动可控，适合“稳健高容量”。
- cybersecurity（高但波动大）：18轮显著低谷（2.827），30轮强力反弹（4.405），对上下文变化敏感。
- cnn（中高、阶段峰）：8–9、25–26轮明显走高，30轮回落（2.568），尾段波动较大。
- art（中等、后段抬升）：21、23、30轮较高（30轮4.224），中前期起伏均衡。
- nlp_transformers（中等偏下、周期性小峰）：10–11、15–16、25–26轮有峰值，整体较为均衡。
- algorithms（较低、后段提升）：27–30轮明显抬升（~3.7–3.81），可作“低容量对照”并观察后期扩展效应。
- mathematics（最低、偶发突起）：14–16、21、29轮有抬升，13与30轮偏低（2.20、2.40），强约束基线特征明显。
### 实验选择建议
- 最大容量通道：ai（全程高位，尤其21–26轮）；稳健高容量：economics（多段平台，波动较小）。
- 动态/波动敏感性测试：cybersecurity、cnn（中后期波动明显）。
- 低容量对照：mathematics、algorithms（可选前期1–6轮或中段低谷轮次）。
- 高熵窗口（便于容量评估的“强带宽”区间，跨题普遍较高）：约在10–12与24–26轮；低谷对照：约在13–15或个别主题的18、30轮。
### 结论
- 收敛性对话的熵并非单调下降，阶段性“议题扩展”会造成后段回升（如ai在26轮、cybersecurity在30轮）。据此进行隐写容量测量，建议报告“峰值区间（如24–26轮）”与“稳态区间（如经济类中段平台）”，并搭配低容量对照（mathematics/algorithms）进行对比。